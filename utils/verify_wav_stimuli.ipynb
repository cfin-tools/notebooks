{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "# This is empirically verified, DO NOT MODIFY\n",
    "PEAK_REL_AMP = 0.563\n",
    "PEAK_REL_AMP_DB = 20. * np.log10(PEAK_REL_AMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Verify WAV stimuli for MEG experiment\n",
    "\n",
    "WAV-files used in the MEG should\n",
    "\n",
    "* be sampled at 44.1 kHz\n",
    "* be saved as 16-bit integer precision\n",
    "\n",
    "If this notebook runs without error, that is the case. In addition, the final plot can be inspected to see the largest absolute amplitude of the stimulus set used. Due to mismatches between the input- and output-levels of the various components in the audio-stream:\n",
    "\n",
    " > __the peak amplitude should never exceed 0.563 (-4.99 dB), _i.e._, 56.3% of maximum volume output__\n",
    " \n",
    " ## Prerequisites\n",
    "\n",
    "You must have the module `meeg-python` in your Python path. A stable version is installed on the servers, but you may also want to clone a copy of the module into your project-folder. If you do so, remember to add the copy to your path. In a notebook, you can achieve this by:\n",
    "\n",
    "```python\n",
    "import sys\n",
    "sys.path.insert(0, '/path/to/your/local/copy/of/meeg-python)\n",
    "```\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why should I verify my WAV stimuli before the MEG experiment?\n",
    "Running this next cell, will show a sine-wave with 2000 V A, getting cut off at 1100V A.\n",
    "This is what will happen to your WAV stimuli, if the WAV file doesn't get attenuated enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "fs = 44100\n",
    "t = np.arange(-0.002, .02, 1.0/fs)\n",
    "f0 = 1000\n",
    "A = 2000\n",
    "x = A * np.sin(2 * np.pi * f0 * t )\n",
    "clipped = np.clip(x,-1100,1100)\n",
    "plt.plot(t, clipped)\n",
    "plt.axis([0, 0.005,-2000, 2000])\n",
    "plt.xlabel('time')\n",
    "plt.ylabel('amplitude')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### File layout\n",
    " To test your own stimuli, you need to set the path to stimuli.\n",
    "* Set the `proj_name` to your project.\n",
    "* Place all the WAV files in a single folder, and set the variable `wav_stimuli` (below) to point to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "proj_name = 'MEG_EEG-Training'\n",
    "wav_stimuli = 'wav_stimuli'\n",
    "wavdir = os.path.join('/aux', proj_name, wav_stimuli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.expanduser(wavdir)):\n",
    "    raise IOError('Invalid wav-directory: {:s}'.format(wavdir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from meeg.wavhelpers import (list_wavs_in_dir, get_wav, wavlist_to_wavarr)\n",
    "Fs = 44100.  # get_wav hard-coded to raise error if not 44.1 kHz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of pathnames to the WAV-files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wavnames = list_wavs_in_dir(wavdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read each WAV into memory\n",
    "\n",
    "Each file is read into a list of 2D-arrays, after which we know the duration of the longest stimulus. The function `wavlist_to_wavarr` then zero-pads each array to have equal duration, and returns a 3D array with dimensions `n_files x n_channels x n_timepoints`, where `n_channels` is either 1 (mono) or 2 (stereo)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wavlist = []\n",
    "for fname in wavnames:\n",
    "    wavlist += [get_wav(fname)]\n",
    "wavarr = wavlist_to_wavarr(wavlist)\n",
    "del wavlist\n",
    "\n",
    "# now data is guaranteed to be 16 bit short\n",
    "maxVal = 2**15 - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot every N:th WAV-file\n",
    "\n",
    "Currently plots only left channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_every_nth = 2\n",
    "timepoints = np.arange(0, wavarr.shape[2]/Fs, 1./Fs)\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "for nwav in range(0, wavarr.shape[0], plot_every_nth):\n",
    "    ax.plot(timepoints, wavarr[nwav,0,:].astype(float) / np.float(maxVal),\n",
    "            label=os.path.basename(wavnames[nwav]))\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The stimulus envelope (peak value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# max_env = np.abs(wavarr).max(axis=0).astype(float) / np.float(maxVal)\n",
    "max_env = 20. * np.log10(np.abs(wavarr).max(axis=0).astype(float) /\n",
    "                         np.float(maxVal))\n",
    "max_stim_env = max_env.max()\n",
    "print('The maximum stimulus envelope is {:.3f} '\n",
    "      '({:.3f} dB)'.format(10**(max_stim_env / 20.), max_stim_env))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A plot of the peak range for all stimuli\n",
    "\n",
    "This plots the peak absolute values of the stimuli, in dB relative to the maximum possible in the 16-bit wav file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "for ww in range(wavarr.shape[0]):\n",
    "    ax.plot(timepoints, \n",
    "            20. * np.log10(np.abs(wavarr[ww, 0, :]).astype(float) /\n",
    "                           np.float(maxVal)),\n",
    "            label=os.path.basename(wavnames[ww]))\n",
    "ax.set_ylim(-9., 0.)\n",
    "ax.legend()\n",
    "_ = ax.set_yticks([0., max_stim_env, -3., -6., -9.])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What should I do with my stimuli?\n",
    "\n",
    "Now that you know the peak envelope of your stimulus set, we can calculate whether and how much additional dampening of the stimuli is required for no clipping to occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "att_factor = PEAK_REL_AMP / 10**(max_stim_env / 20.)\n",
    "if max_stim_env > PEAK_REL_AMP_DB:\n",
    "    print('You should attenuate your stimuli by '\n",
    "          'a factor of {:.3f} ({:.3f} dB)'.format(att_factor,\n",
    "                                                  20 * np.log10(att_factor)))\n",
    "else:\n",
    "    print('Your stimuli are sufficiently damped, '\n",
    "          'you are using {:.1f}% of the range.'.format(100./att_factor))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
